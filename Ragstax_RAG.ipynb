{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UdG7tVlFRrP"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datastax/ragstack-ai/blob/main/examples/notebooks/quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCB_JIPZFRrT"
      },
      "source": [
        "## Setup\n",
        "`ragstack-ai` includes all the packages you need to build a RAG pipeline.\n",
        "\n",
        "`datasets` is used to import a sample dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "nbmake": {
          "post_cell_execute": [
            "from conftest import before_notebook",
            "before_notebook()"
          ]
        },
        "tags": [],
        "id": "eFXXF93XFRrU"
      },
      "outputs": [],
      "source": [
        "! pip install -q ragstack-ai datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "nbmake": {
          "post_cell_execute": [
            "import string\n",
            "import random\n",
            "collection = ''.join(random.choice(string.ascii_lowercase) for _ in range(8))\n"
          ]
        },
        "tags": [
          "skip-execution"
        ],
        "id": "x1ifzusxFRrU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Enter your settings for Astra DB and OpenAI:\n",
        "os.environ[\"ASTRA_DB_API_ENDPOINT\"] = getpass(\"Enter your Astra DB API Endpoint:\")\n",
        "os.environ[\"ASTRA_DB_APPLICATION_TOKEN\"] = getpass(\"Enter your Astra DB Token:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gh8rtZiIFRrV"
      },
      "source": [
        "## Create RAG Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2EsRLW4FRrV"
      },
      "source": [
        "### Embedding Model and Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "VHX2H1zwFRrV"
      },
      "outputs": [],
      "source": [
        "from langchain_astradb import AstraDBVectorStore\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "import os\n",
        "\n",
        "# Configure your embedding model and vector store\n",
        "embedding = OpenAIEmbeddings()\n",
        "vstore = AstraDBVectorStore(\n",
        "    collection_name=\"test\",\n",
        "    embedding=embedding,\n",
        "    token=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\"),\n",
        "    api_endpoint=os.getenv(\"ASTRA_DB_API_ENDPOINT\"),\n",
        ")\n",
        "print(\"Astra vector store configured\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9R7XY1nVFRrW"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load a sample dataset\n",
        "philo_dataset = load_dataset(\"datastax/philosopher-quotes\")[\"train\"]\n",
        "print(\"An example entry:\")\n",
        "print(philo_dataset[16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDGJa1Q1FRrW"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document\n",
        "\n",
        "# Constructs a set of documents from your data. Documents can be used as inputs to your vector store.\n",
        "docs = []\n",
        "for entry in philo_dataset:\n",
        "    metadata = {\"author\": entry[\"author\"]}\n",
        "    if entry[\"tags\"]:\n",
        "        # Add metadata tags to the metadata dictionary\n",
        "        for tag in entry[\"tags\"].split(\";\"):\n",
        "            metadata[tag] = \"y\"\n",
        "    # Create a LangChain document with the quote and metadata tags\n",
        "    doc = Document(page_content=entry[\"quote\"], metadata=metadata)\n",
        "    docs.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "id": "Qj9Vfp1yaHe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbmake": {
          "post_cell_execute": [
            "assert len(inserted_ids) > 0"
          ]
        },
        "id": "tic5aER5FRrW"
      },
      "outputs": [],
      "source": [
        "# Create embeddings by inserting your documents into the vector store.\n",
        "inserted_ids = vstore.add_documents(docs)\n",
        "print(f\"\\nInserted {len(inserted_ids)} documents.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "id": "d8A0Vx3SFRrX"
      },
      "outputs": [],
      "source": [
        "# Checks your collection to verify the documents are embedded.\n",
        "print(vstore.astra_db.collection(\"test\").find())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZeIZTjkFRrX"
      },
      "source": [
        "### Basic Retrieval\n",
        "\n",
        "Retrieve context from vector database, and pass it to the model with a prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-trtVrWFRrX"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "\n",
        "retriever = vstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "Answer the question based only on the supplied context. If you don't know the answer, say you don't know the answer.\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "Your answer:\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "model = ChatOpenAI()\n",
        "\n",
        "chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "chain.invoke(\"In the given context, what is the most important to allow the brain and provide me the tags?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9Iv1e24FRrX"
      },
      "outputs": [],
      "source": [
        "# Add questions here\n",
        "chain.invoke(\"<your question>\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1MT_ytSFRrX"
      },
      "source": [
        "## Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "nbmake": {
          "post_cell_execute": [
            "# Deletes collection for test suite to allow each test to run with a fresh collection",
            "vstore.delete_collection()"
          ]
        },
        "id": "QannnHWhFRrX"
      },
      "outputs": [],
      "source": [
        "# WARNING: This will delete the collection and all documents in the collection\n",
        "vstore.delete_collection()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}